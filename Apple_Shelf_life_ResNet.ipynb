{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apple-Shelf-life ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj7rTfREIaub",
        "outputId": "82247920-6be2-4afa-ea11-d8bb9edfac0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.37.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.13.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.44.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu==2.3.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ALz_SBvDJzil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Apple dataset/Train'\n",
        "valid_path = '/content/drive/MyDrive/Apple dataset/Test'\n"
      ],
      "metadata": {
        "id": "q6cx21QMKT2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ResNet50 library as shown below and add preprocessing layer to the front of ResNet\n",
        "# Here we will be using imagenet weights\n",
        "\n",
        "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n"
      ],
      "metadata": {
        "id": "TH-eWcF2KjCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# don't train existing weights\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "at0fmHvZKjOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # useful for getting number of output classes\n",
        "folders = glob('/content/drive/MyDrive/Apple dataset/Train/*')\n",
        "print(len(folders))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDBk_-AfLD2q",
        "outputId": "effdb939-a24d-4d9f-f8c5-8ef73a602093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# our layers -we can add more if we wantx = Flatten()(resnet.output)\n",
        "x = Flatten()(resnet.output)\n"
      ],
      "metadata": {
        "id": "LfOBCapmLOAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "# as there are 3 classes for predicting shelf life \n",
        "# that's why we use softmax as activtion function\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=resnet.input, outputs=prediction)\n",
        "\n"
      ],
      "metadata": {
        "id": "sb-1wdRJLe1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the structure of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZZ5R4-uL7EK",
        "outputId": "352f654d-be6c-4b86-bc2f-5473e7b63bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 100352)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 3)            301059      flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,888,771\n",
            "Trainable params: 301,059\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "hLjEf4QYMJ6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augumentation\n",
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
      ],
      "metadata": {
        "id": "jI2TQoGTMXO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Apple dataset/Train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 16,\n",
        "                                                 class_mode = 'categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYwnqt21Muh8",
        "outputId": "22e0a0a4-f6e8-49b7-d1d2-4d643985f9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 460 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Apple dataset/Test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 16,\n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vZU_45xUQ12",
        "outputId": "52ba0bed-e222-4e13-d9d7-869d4cf008a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 148 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=100,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTdPDP6VUlR9",
        "outputId": "f0a28d0d-75e5-46e4-d759-091b9f2d69b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 12s 397ms/step - loss: 0.9009 - accuracy: 0.7022 - val_loss: 1.5743 - val_accuracy: 0.5743\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.8378 - accuracy: 0.6674 - val_loss: 0.9202 - val_accuracy: 0.5878\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 0.6394 - accuracy: 0.7261 - val_loss: 0.8325 - val_accuracy: 0.6757\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.9461 - accuracy: 0.6413 - val_loss: 1.1690 - val_accuracy: 0.6757\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 1.1760 - accuracy: 0.6413 - val_loss: 1.1373 - val_accuracy: 0.7162\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.0616 - accuracy: 0.6217 - val_loss: 1.3996 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 0.6518 - accuracy: 0.7391 - val_loss: 0.7140 - val_accuracy: 0.7432\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 1.3091 - accuracy: 0.6326 - val_loss: 1.3089 - val_accuracy: 0.5946\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.2620 - accuracy: 0.6043 - val_loss: 3.5066 - val_accuracy: 0.3581\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 9s 316ms/step - loss: 1.0691 - accuracy: 0.6283 - val_loss: 0.6246 - val_accuracy: 0.7365\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 9s 318ms/step - loss: 0.6128 - accuracy: 0.7261 - val_loss: 1.0946 - val_accuracy: 0.5068\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 9s 323ms/step - loss: 0.6788 - accuracy: 0.7283 - val_loss: 0.6145 - val_accuracy: 0.7432\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 9s 313ms/step - loss: 0.9200 - accuracy: 0.6478 - val_loss: 0.9982 - val_accuracy: 0.5878\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 9s 313ms/step - loss: 1.0961 - accuracy: 0.6370 - val_loss: 1.4894 - val_accuracy: 0.4662\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 1.2050 - accuracy: 0.6109 - val_loss: 2.1368 - val_accuracy: 0.4797\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 0.9370 - accuracy: 0.6522 - val_loss: 1.0998 - val_accuracy: 0.7027\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 0.7716 - accuracy: 0.6739 - val_loss: 0.9629 - val_accuracy: 0.6419\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.7082 - accuracy: 0.7152 - val_loss: 0.7661 - val_accuracy: 0.5473\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 1.0333 - accuracy: 0.6304 - val_loss: 0.7843 - val_accuracy: 0.7095\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.5960 - accuracy: 0.7370 - val_loss: 0.7812 - val_accuracy: 0.5946\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 9s 313ms/step - loss: 0.8154 - accuracy: 0.6739 - val_loss: 1.0176 - val_accuracy: 0.5473\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.8127 - accuracy: 0.6783 - val_loss: 0.6886 - val_accuracy: 0.7230\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.7745 - accuracy: 0.7000 - val_loss: 0.9352 - val_accuracy: 0.6081\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.5818 - accuracy: 0.7565 - val_loss: 0.8498 - val_accuracy: 0.6014\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 0.6806 - accuracy: 0.7261 - val_loss: 0.7133 - val_accuracy: 0.7297\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.9166 - accuracy: 0.6500 - val_loss: 2.1269 - val_accuracy: 0.5473\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.1087 - accuracy: 0.6435 - val_loss: 1.0446 - val_accuracy: 0.7095\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 0.5955 - accuracy: 0.7522 - val_loss: 0.5724 - val_accuracy: 0.6959\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 9s 314ms/step - loss: 0.5594 - accuracy: 0.7652 - val_loss: 1.3712 - val_accuracy: 0.5878\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 1.0825 - accuracy: 0.6739 - val_loss: 0.7312 - val_accuracy: 0.7365\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.5973 - accuracy: 0.7630 - val_loss: 0.5524 - val_accuracy: 0.7297\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.8999 - accuracy: 0.6913 - val_loss: 1.3025 - val_accuracy: 0.5878\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 1.0217 - accuracy: 0.6522 - val_loss: 0.6136 - val_accuracy: 0.6216\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 0.7766 - accuracy: 0.6804 - val_loss: 0.9307 - val_accuracy: 0.5270\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.7757 - accuracy: 0.7261 - val_loss: 0.6761 - val_accuracy: 0.6486\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 1.0011 - accuracy: 0.6435 - val_loss: 1.5392 - val_accuracy: 0.5811\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 1.2372 - accuracy: 0.6804 - val_loss: 0.6337 - val_accuracy: 0.8108\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.3192 - accuracy: 0.6109 - val_loss: 1.1060 - val_accuracy: 0.5743\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 1.3248 - accuracy: 0.6261 - val_loss: 2.2264 - val_accuracy: 0.5878\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 0.7018 - accuracy: 0.7413 - val_loss: 0.7223 - val_accuracy: 0.7365\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.8991 - accuracy: 0.6891 - val_loss: 0.5531 - val_accuracy: 0.7635\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.8253 - accuracy: 0.6783 - val_loss: 0.8106 - val_accuracy: 0.6419\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.9404 - accuracy: 0.6674 - val_loss: 0.5449 - val_accuracy: 0.6892\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 0.6913 - accuracy: 0.7413 - val_loss: 0.5083 - val_accuracy: 0.7162\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 9s 320ms/step - loss: 0.6102 - accuracy: 0.7500 - val_loss: 0.7230 - val_accuracy: 0.7027\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 0.5943 - accuracy: 0.7587 - val_loss: 0.9856 - val_accuracy: 0.5743\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.5692 - accuracy: 0.7543 - val_loss: 0.4951 - val_accuracy: 0.8108\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.5294 - accuracy: 0.7783 - val_loss: 0.6405 - val_accuracy: 0.6892\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.6006 - accuracy: 0.7457 - val_loss: 0.7633 - val_accuracy: 0.6486\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 0.4995 - accuracy: 0.7739 - val_loss: 0.4551 - val_accuracy: 0.8108\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.5621 - accuracy: 0.7609 - val_loss: 0.7819 - val_accuracy: 0.6216\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 0.7800 - accuracy: 0.7022 - val_loss: 0.9867 - val_accuracy: 0.6149\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 0.5238 - accuracy: 0.7935 - val_loss: 0.5063 - val_accuracy: 0.8446\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.6473 - accuracy: 0.7261 - val_loss: 0.6321 - val_accuracy: 0.6622\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.6132 - accuracy: 0.7522 - val_loss: 0.5057 - val_accuracy: 0.7568\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.6267 - accuracy: 0.7522 - val_loss: 0.7150 - val_accuracy: 0.5878\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 0.7140 - accuracy: 0.7435 - val_loss: 1.0398 - val_accuracy: 0.5946\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 0.6204 - accuracy: 0.7652 - val_loss: 0.7318 - val_accuracy: 0.5541\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.5692 - accuracy: 0.7848 - val_loss: 1.2907 - val_accuracy: 0.5676\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.5739 - accuracy: 0.7609 - val_loss: 0.6858 - val_accuracy: 0.7568\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.6244 - accuracy: 0.7370 - val_loss: 0.8004 - val_accuracy: 0.6149\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.7769 - accuracy: 0.7130 - val_loss: 0.8898 - val_accuracy: 0.6284\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.6184 - accuracy: 0.7413 - val_loss: 0.6498 - val_accuracy: 0.7703\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 9s 313ms/step - loss: 0.7282 - accuracy: 0.7283 - val_loss: 0.6568 - val_accuracy: 0.6351\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 1.0579 - accuracy: 0.6630 - val_loss: 1.5027 - val_accuracy: 0.6486\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.7878 - accuracy: 0.7022 - val_loss: 0.5417 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.6249 - accuracy: 0.7696 - val_loss: 0.7093 - val_accuracy: 0.5811\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.4395 - accuracy: 0.8174 - val_loss: 0.5928 - val_accuracy: 0.7365\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 0.6190 - accuracy: 0.7696 - val_loss: 0.9454 - val_accuracy: 0.6149\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.5905 - accuracy: 0.7413 - val_loss: 0.9556 - val_accuracy: 0.6351\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 1.2069 - accuracy: 0.6174 - val_loss: 1.3599 - val_accuracy: 0.5203\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 1.1636 - accuracy: 0.6326 - val_loss: 0.8998 - val_accuracy: 0.5405\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.5028 - accuracy: 0.8043 - val_loss: 1.7468 - val_accuracy: 0.5473\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.8033 - accuracy: 0.7065 - val_loss: 0.6906 - val_accuracy: 0.6351\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.4984 - accuracy: 0.7870 - val_loss: 0.6173 - val_accuracy: 0.7635\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.5482 - accuracy: 0.7935 - val_loss: 0.9332 - val_accuracy: 0.6689\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 1.0001 - accuracy: 0.6913 - val_loss: 0.8081 - val_accuracy: 0.6689\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 9s 319ms/step - loss: 0.9973 - accuracy: 0.6630 - val_loss: 0.6265 - val_accuracy: 0.6689\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 0.9468 - accuracy: 0.6826 - val_loss: 0.8117 - val_accuracy: 0.6689\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 0.6823 - accuracy: 0.7565 - val_loss: 0.6272 - val_accuracy: 0.7027\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 0.5311 - accuracy: 0.7848 - val_loss: 0.6099 - val_accuracy: 0.7027\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 0.5128 - accuracy: 0.7891 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 0.5351 - accuracy: 0.7761 - val_loss: 0.6235 - val_accuracy: 0.6824\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.5025 - accuracy: 0.7913 - val_loss: 0.5039 - val_accuracy: 0.8446\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 0.4504 - accuracy: 0.8304 - val_loss: 0.7544 - val_accuracy: 0.6892\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 0.4826 - accuracy: 0.7848 - val_loss: 1.6015 - val_accuracy: 0.5135\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 0.6613 - accuracy: 0.7283 - val_loss: 1.4942 - val_accuracy: 0.5473\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.8896 - accuracy: 0.6630 - val_loss: 1.1886 - val_accuracy: 0.6419\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 0.9420 - accuracy: 0.6913 - val_loss: 1.0687 - val_accuracy: 0.6284\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 0.8833 - accuracy: 0.7196 - val_loss: 0.5272 - val_accuracy: 0.8311\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.6516 - accuracy: 0.7543 - val_loss: 1.0084 - val_accuracy: 0.6351\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.5648 - accuracy: 0.7391 - val_loss: 0.5287 - val_accuracy: 0.7568\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.9645 - accuracy: 0.6848 - val_loss: 0.5736 - val_accuracy: 0.6959\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 9s 305ms/step - loss: 1.3605 - accuracy: 0.5870 - val_loss: 1.1708 - val_accuracy: 0.7027\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 9s 306ms/step - loss: 1.0286 - accuracy: 0.6848 - val_loss: 0.8247 - val_accuracy: 0.7838\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 9s 306ms/step - loss: 0.7499 - accuracy: 0.7022 - val_loss: 0.9540 - val_accuracy: 0.7432\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 0.4538 - accuracy: 0.8196 - val_loss: 0.7079 - val_accuracy: 0.7297\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 0.5730 - accuracy: 0.7826 - val_loss: 0.8701 - val_accuracy: 0.5743\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 0.4502 - accuracy: 0.8130 - val_loss: 0.6236 - val_accuracy: 0.7027\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 0.5118 - accuracy: 0.7978 - val_loss: 0.5188 - val_accuracy: 0.7162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "path=\"/content/drive/MyDrive/model_ResNet(accuracy=79).h5\"\n",
        "model.save(path)\n"
      ],
      "metadata": {
        "id": "t35gPZ9GdJdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(test_set)"
      ],
      "metadata": {
        "id": "DEwN7cLCf9_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9PferB1gDi1",
        "outputId": "54b15aed-4969-4e20-9dce-b5106980786f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.56532121e-06, 9.99995947e-01, 2.48351330e-06],\n",
              "       [6.58134639e-01, 2.03536734e-01, 1.38328627e-01],\n",
              "       [3.08404607e-03, 5.64343203e-03, 9.91272509e-01],\n",
              "       [2.63646007e-01, 4.40547317e-01, 2.95806736e-01],\n",
              "       [2.34181091e-01, 3.78366172e-01, 3.87452692e-01],\n",
              "       [1.28493886e-02, 9.77326810e-01, 9.82382149e-03],\n",
              "       [6.02306902e-01, 2.90642842e-03, 3.94786686e-01],\n",
              "       [2.85679311e-01, 6.11444294e-01, 1.02876335e-01],\n",
              "       [2.97096938e-01, 5.98039508e-01, 1.04863591e-01],\n",
              "       [1.25549696e-02, 9.79602993e-01, 7.84193724e-03],\n",
              "       [2.43194148e-01, 5.55348635e-01, 2.01457217e-01],\n",
              "       [6.55891793e-03, 4.68189895e-01, 5.25251150e-01],\n",
              "       [2.45939106e-01, 3.83384468e-04, 7.53677547e-01],\n",
              "       [5.66002131e-01, 4.33031842e-03, 4.29667532e-01],\n",
              "       [2.71403207e-03, 4.26898198e-03, 9.93016958e-01],\n",
              "       [7.04310238e-01, 1.90643303e-03, 2.93783367e-01],\n",
              "       [2.05020204e-01, 7.78871588e-04, 7.94200957e-01],\n",
              "       [1.55919909e-01, 5.67900896e-01, 2.76179254e-01],\n",
              "       [6.07338222e-03, 3.16072911e-01, 6.77853703e-01],\n",
              "       [6.53597235e-04, 7.88174987e-01, 2.11171404e-01],\n",
              "       [1.48225517e-04, 9.70419645e-01, 2.94321813e-02],\n",
              "       [6.07946277e-01, 2.19348773e-01, 1.72704920e-01],\n",
              "       [2.64513940e-01, 5.24975777e-01, 2.10510328e-01],\n",
              "       [6.17435992e-01, 2.99352314e-03, 3.79570484e-01],\n",
              "       [7.47624226e-03, 9.91350293e-01, 1.17348612e-03],\n",
              "       [7.56177306e-03, 3.49320035e-04, 9.92088914e-01],\n",
              "       [7.04125734e-03, 3.83169532e-01, 6.09789193e-01],\n",
              "       [7.52560709e-07, 9.99998808e-01, 4.81349559e-07],\n",
              "       [2.45144516e-01, 5.78116357e-01, 1.76739112e-01],\n",
              "       [4.63534845e-03, 1.18324650e-04, 9.95246351e-01],\n",
              "       [6.02379534e-03, 2.98738629e-01, 6.95237577e-01],\n",
              "       [2.29451805e-01, 3.88763070e-01, 3.81785095e-01],\n",
              "       [3.02905613e-03, 4.00601467e-03, 9.92964864e-01],\n",
              "       [9.01166081e-01, 5.45665845e-02, 4.42673564e-02],\n",
              "       [2.61519074e-01, 5.13527334e-01, 2.24953637e-01],\n",
              "       [2.41829887e-01, 5.86170971e-01, 1.71999142e-01],\n",
              "       [4.49381190e-07, 9.99999285e-01, 1.86943211e-07],\n",
              "       [8.37407168e-03, 4.79668491e-02, 9.43659067e-01],\n",
              "       [1.39093900e-04, 9.72391546e-01, 2.74693277e-02],\n",
              "       [9.74750519e-03, 9.84402657e-01, 5.84982801e-03],\n",
              "       [3.87633600e-06, 9.99980807e-01, 1.52650609e-05],\n",
              "       [1.38488103e-04, 9.73656416e-01, 2.62050685e-02],\n",
              "       [3.01126670e-03, 4.45790356e-03, 9.92530882e-01],\n",
              "       [1.35047734e-02, 9.76914465e-01, 9.58085805e-03],\n",
              "       [9.11267102e-03, 9.87990677e-01, 2.89660669e-03],\n",
              "       [1.96754816e-03, 9.29866374e-01, 6.81660399e-02],\n",
              "       [6.98695779e-02, 2.00344607e-01, 7.29785860e-01],\n",
              "       [2.01379806e-01, 7.35785055e-04, 7.97884405e-01],\n",
              "       [6.22827470e-01, 1.26485616e-01, 2.50686944e-01],\n",
              "       [2.77073085e-01, 3.64392996e-01, 3.58533949e-01],\n",
              "       [7.81770945e-01, 9.27690491e-02, 1.25460029e-01],\n",
              "       [2.22211555e-02, 9.68962193e-01, 8.81675631e-03],\n",
              "       [1.34259425e-02, 9.78635132e-01, 7.93890469e-03],\n",
              "       [5.95759461e-03, 1.88654245e-04, 9.93853807e-01],\n",
              "       [1.52639099e-04, 9.71410096e-01, 2.84372512e-02],\n",
              "       [2.72847235e-01, 3.03578447e-04, 7.26849198e-01],\n",
              "       [3.69670540e-02, 9.51304972e-01, 1.17279282e-02],\n",
              "       [6.02603219e-02, 1.35979772e-01, 8.03759873e-01],\n",
              "       [5.94805300e-01, 3.22797010e-03, 4.01966721e-01],\n",
              "       [6.77881658e-01, 1.97839434e-03, 3.20139915e-01],\n",
              "       [1.36470119e-03, 9.53747392e-01, 4.48879004e-02],\n",
              "       [2.56153359e-03, 2.50038773e-01, 7.47399688e-01],\n",
              "       [5.73255241e-01, 1.82870924e-01, 2.43873835e-01],\n",
              "       [4.22426005e-04, 9.86662209e-01, 1.29154045e-02],\n",
              "       [1.29820984e-02, 9.85449910e-01, 1.56791916e-03],\n",
              "       [2.43523587e-02, 9.72746968e-01, 2.90064374e-03],\n",
              "       [9.72495154e-02, 3.13501358e-01, 5.89249134e-01],\n",
              "       [2.92479008e-01, 6.02155149e-01, 1.05365872e-01],\n",
              "       [2.30586469e-01, 6.43245101e-01, 1.26168415e-01],\n",
              "       [5.41155413e-03, 1.96108405e-04, 9.94392335e-01],\n",
              "       [1.41286670e-04, 9.71674383e-01, 2.81842761e-02],\n",
              "       [2.22846508e-01, 4.09165889e-01, 3.67987603e-01],\n",
              "       [5.41028202e-01, 4.91626188e-03, 4.54055548e-01],\n",
              "       [9.16014519e-03, 5.47791366e-04, 9.90292132e-01],\n",
              "       [2.31006995e-01, 4.08849865e-01, 3.60143185e-01],\n",
              "       [4.89080441e-04, 8.56253266e-01, 1.43257722e-01],\n",
              "       [2.74482439e-03, 4.68630064e-03, 9.92568791e-01],\n",
              "       [2.72950232e-01, 5.99883020e-01, 1.27166778e-01],\n",
              "       [1.43670404e-04, 9.73405719e-01, 2.64506508e-02],\n",
              "       [2.36515656e-01, 5.75021744e-01, 1.88462630e-01],\n",
              "       [1.02042202e-02, 9.85974729e-01, 3.82104306e-03],\n",
              "       [2.89561949e-03, 3.39999213e-03, 9.93704379e-01],\n",
              "       [5.36301173e-04, 9.85424936e-01, 1.40388347e-02],\n",
              "       [1.75437350e-02, 9.80898738e-01, 1.55753258e-03],\n",
              "       [9.02279973e-01, 5.43511212e-02, 4.33688723e-02],\n",
              "       [6.14230931e-02, 1.57844841e-01, 7.80732036e-01],\n",
              "       [4.06570174e-02, 8.67823482e-01, 9.15195718e-02],\n",
              "       [1.97597928e-02, 9.38951433e-01, 4.12888490e-02],\n",
              "       [2.95234006e-03, 4.18979954e-03, 9.92857814e-01],\n",
              "       [1.33740032e-04, 9.74553525e-01, 2.53126826e-02],\n",
              "       [3.00991029e-01, 5.90470672e-01, 1.08538270e-01],\n",
              "       [2.40794405e-01, 3.66602212e-01, 3.92603338e-01],\n",
              "       [2.66260177e-01, 2.00124472e-04, 7.33539701e-01],\n",
              "       [4.80432948e-03, 9.94178653e-01, 1.01702369e-03],\n",
              "       [2.64223039e-01, 5.07224321e-01, 2.28552610e-01],\n",
              "       [5.51273644e-01, 1.59056574e-01, 2.89669782e-01],\n",
              "       [6.08076155e-03, 4.57240134e-01, 5.36679089e-01],\n",
              "       [3.86510864e-02, 8.82459998e-01, 7.88889006e-02],\n",
              "       [2.25608617e-01, 4.01812822e-01, 3.72578532e-01],\n",
              "       [2.73406948e-03, 5.41403610e-03, 9.91851866e-01],\n",
              "       [6.21300220e-01, 2.06933931e-01, 1.71765760e-01],\n",
              "       [2.91941941e-01, 6.02804303e-01, 1.05253771e-01],\n",
              "       [8.47280119e-03, 9.88723993e-01, 2.80314265e-03],\n",
              "       [9.36605856e-02, 2.60207027e-01, 6.46132350e-01],\n",
              "       [2.40134001e-01, 6.30123556e-01, 1.29742369e-01],\n",
              "       [6.41199231e-01, 1.22529738e-01, 2.36271009e-01],\n",
              "       [2.83992570e-03, 3.53023503e-03, 9.93629873e-01],\n",
              "       [1.55159592e-04, 9.70741928e-01, 2.91029178e-02],\n",
              "       [5.69272637e-01, 3.96522880e-03, 4.26762134e-01],\n",
              "       [3.11294198e-01, 5.77704132e-01, 1.11001618e-01],\n",
              "       [2.63432771e-01, 5.12400329e-01, 2.24166885e-01],\n",
              "       [2.59461313e-01, 5.28618574e-01, 2.11920112e-01],\n",
              "       [1.33699505e-04, 9.74527717e-01, 2.53385082e-02],\n",
              "       [6.44397736e-01, 1.96464419e-01, 1.59137860e-01],\n",
              "       [6.37872934e-01, 1.97718441e-01, 1.64408579e-01],\n",
              "       [5.46684921e-01, 1.41630277e-01, 3.11684817e-01],\n",
              "       [4.18072773e-07, 9.99999404e-01, 1.64248860e-07],\n",
              "       [1.15379435e-03, 9.63609040e-01, 3.52371335e-02],\n",
              "       [2.85838940e-03, 2.92055637e-01, 7.05085993e-01],\n",
              "       [1.94853856e-05, 9.99980330e-01, 2.95528736e-07],\n",
              "       [6.96610892e-03, 2.43589625e-01, 7.49444246e-01],\n",
              "       [1.51295360e-04, 9.71426725e-01, 2.84219589e-02],\n",
              "       [3.34214582e-03, 3.55758029e-03, 9.93100286e-01],\n",
              "       [1.45378348e-04, 9.72286642e-01, 2.75680535e-02],\n",
              "       [2.26537463e-06, 9.99992371e-01, 5.35522486e-06],\n",
              "       [1.21783353e-01, 5.75806946e-04, 8.77640843e-01],\n",
              "       [2.43960515e-01, 6.27590477e-01, 1.28448978e-01],\n",
              "       [2.24501088e-01, 6.52172267e-01, 1.23326674e-01],\n",
              "       [6.15129650e-01, 2.14767367e-01, 1.70102969e-01],\n",
              "       [3.03571105e-01, 5.80110133e-01, 1.16318814e-01],\n",
              "       [1.42587902e-04, 9.71323371e-01, 2.85341069e-02],\n",
              "       [2.85485946e-03, 3.46936565e-03, 9.93675768e-01],\n",
              "       [2.54648656e-01, 2.60840810e-04, 7.45090485e-01],\n",
              "       [7.00959623e-01, 1.72913109e-03, 2.97311217e-01],\n",
              "       [2.30445847e-01, 5.22421789e-04, 7.69031703e-01],\n",
              "       [9.70807672e-03, 4.80848961e-02, 9.42207038e-01],\n",
              "       [6.42486382e-03, 2.76176661e-01, 7.17398465e-01],\n",
              "       [1.47627783e-04, 9.70457554e-01, 2.93948762e-02],\n",
              "       [5.91816427e-03, 3.09559405e-01, 6.84522450e-01],\n",
              "       [9.55535471e-03, 9.88836408e-01, 1.60816149e-03],\n",
              "       [5.07755544e-07, 9.99999404e-01, 1.45895925e-07],\n",
              "       [8.98735762e-01, 5.56563623e-02, 4.56078835e-02],\n",
              "       [1.42997997e-02, 9.68760312e-01, 1.69398785e-02],\n",
              "       [5.47707081e-03, 5.68187416e-01, 4.26335484e-01],\n",
              "       [2.52285868e-01, 5.60606897e-01, 1.87107280e-01],\n",
              "       [2.74491370e-01, 3.67187470e-01, 3.58321220e-01],\n",
              "       [2.96879589e-05, 9.99969840e-01, 5.28928126e-07],\n",
              "       [8.21079936e-07, 9.99998450e-01, 7.51023322e-07]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred=np.argmax(y_pred,axis=1)"
      ],
      "metadata": {
        "id": "L83m3RXHgF8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIotfv_YgUeq",
        "outputId": "0215fdf4-8006-40da-9468-ddfd10f9b71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 2, 1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 2, 1, 2, 1, 1, 0,\n",
              "       1, 0, 1, 2, 2, 1, 1, 2, 2, 1, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1,\n",
              "       1, 1, 2, 2, 0, 1, 0, 1, 1, 2, 1, 2, 1, 2, 0, 0, 1, 2, 0, 1, 1, 1,\n",
              "       2, 1, 1, 2, 1, 1, 0, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 1,\n",
              "       2, 1, 1, 2, 2, 1, 1, 0, 2, 1, 1, 2, 0, 1, 1, 2, 1, 0, 2, 1, 0, 1,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 0, 1, 1, 2,\n",
              "       2, 0, 2, 2, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "nORLchpsgWYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model('/content/drive/MyDrive/model_ResNet(accuracy=79).h5')"
      ],
      "metadata": {
        "id": "qxVcbeblgs9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=image.load_img('/content/drive/MyDrive/Apple dataset/Train/Apple(1-5)/frame1010.jpg',target_size=(224,224))"
      ],
      "metadata": {
        "id": "jZrGy--QhBzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=image.img_to_array(img)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FoZtmbohS5m",
        "outputId": "46fc37dc-5a78-4f8f-8ec6-e67e67789bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        ...,\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.]],\n",
              "\n",
              "       [[255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        ...,\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.]],\n",
              "\n",
              "       [[255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        ...,\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.],\n",
              "        [255., 255., 255.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[222., 222., 222.],\n",
              "        [222., 222., 222.],\n",
              "        [222., 222., 222.],\n",
              "        ...,\n",
              "        [ 51.,  35.,  22.],\n",
              "        [ 51.,  35.,  22.],\n",
              "        [ 55.,  37.,  23.]],\n",
              "\n",
              "       [[223., 223., 223.],\n",
              "        [223., 223., 223.],\n",
              "        [223., 223., 223.],\n",
              "        ...,\n",
              "        [ 28.,  26.,  14.],\n",
              "        [ 28.,  26.,  14.],\n",
              "        [ 30.,  26.,  15.]],\n",
              "\n",
              "       [[222., 222., 222.],\n",
              "        [222., 222., 222.],\n",
              "        [222., 222., 222.],\n",
              "        ...,\n",
              "        [164., 167., 160.],\n",
              "        [164., 167., 160.],\n",
              "        [162., 165., 156.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHq3BV-hhbQc",
        "outputId": "798fea56-ca74-4e15-9880-fb3fa73e70b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=x/255"
      ],
      "metadata": {
        "id": "7L0HlvdYhefp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.expand_dims(x,axis=0)\n",
        "img_data=preprocess_input(x)\n",
        "img_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEMVEDdGhjED",
        "outputId": "0beee915-c52b-454a-c43d-5fe23f07183a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(img_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4fabT2_hojP",
        "outputId": "ffe3bc6b-4a15-47c3-b427-58eb102cc532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.000000e+00, 0.000000e+00, 3.023413e-26]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.argmax(model.predict(img_data),axis=1)"
      ],
      "metadata": {
        "id": "ZIdVpPokhuFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a[0])\n",
        "if a[0]==0:\n",
        "  print(\"predicted Shelf-life is about (1-5)\")\n",
        "elif a[0]==1:\n",
        "  print(\"predicted Shelf life is about (10-14)\")\n",
        "else:\n",
        "  print(\"predicted Shelf life is about (10-14)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnLZCUyfhwj0",
        "outputId": "ce8b51ce-8e33-4010-dfd2-53f625ad7df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "predicted Shelf-life is about (1-5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "si0anf1Lh1v5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}